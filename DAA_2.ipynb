{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6853193a",
   "metadata": {},
   "source": [
    "**Задача**: предсказание баллов ЕГЭ ученика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[   1,    1,  500,    1],\n",
    "              [   1,    1,  700,    1],\n",
    "              [   1,    2,  750,    2],\n",
    "              [   1,    5,  600,    1],\n",
    "              [   1,    3, 1450,    2],\n",
    "              [   1,    0,  800,    1],\n",
    "              [   1,    5, 1500,    3],\n",
    "              [   1,   10, 2000,    3],\n",
    "              [   1,    1,  450,    1],\n",
    "              [   1,    2, 1000,    2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae9a29",
   "metadata": {},
   "source": [
    "**2. Можно ли к одному и тому же признаку применить сразу и нормализацию, и стандартизацию?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41127a4a",
   "metadata": {},
   "source": [
    "Нормализация [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1].min(), X[:, 1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 2].min(), X[:, 2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X):\n",
    "    return (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdff82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = X.copy()\n",
    "X_norm = X_norm.astype(np.float64)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c00837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm[:, 1] = min_max_scale(X_norm[:, 1])\n",
    "X_norm[:, 2] = min_max_scale(X_norm[:, 2])\n",
    "X_norm[:, 3] = min_max_scale(X_norm[:, 3])\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1d392",
   "metadata": {},
   "source": [
    "Стандартизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1872b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X[:, 1]))\n",
    "plt.hist(X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X[:, 2]))\n",
    "plt.hist(X[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X):\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.astype(np.float64)\n",
    "X_st[:, 1] = standard_scale(X_st[:, 1])\n",
    "X_st[:, 2] = standard_scale(X_st[:, 2])\n",
    "X_st[:, 3] = standard_scale(X_st[:, 3])\n",
    "\n",
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd71e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_st[:, 1]))\n",
    "print(np.std(X_st[:, 1]))\n",
    "\n",
    "plt.hist(X_st[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ce894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_st[:, 2]))\n",
    "print(np.std(X_st[:, 2]))\n",
    "\n",
    "plt.hist(X_st[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947ae0f",
   "metadata": {},
   "source": [
    "**Ответ:** Можно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(X.shape[1])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8044eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# классический  GD\n",
    "def gradient_descent(X, y, iterations, eta=1e-4):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        y_pred = np.dot(X, W)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        dQ = 2/n * X.T @ (y_pred - y) # градиент функции ошибки\n",
    "        W -= (eta * dQ)\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(X_st, y, iterations=5000, eta=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef335ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# стохастический градиентный спуск\n",
    "def stohastic_gradient_descent(X, y, iterations, batch_size, eta=1e-4):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    n_batch = n // batch_size    \n",
    "    if n % batch_size != 0:\n",
    "        n_batch += 1\n",
    "    print(f'amount of batches is {n_batch}')\n",
    "        \n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        for b in range(n_batch):\n",
    "            inds = np.random.randint(n, size=batch_size)\n",
    "\n",
    "            X_tmp = X[inds, ]\n",
    "            y_tmp = np.array(y)[inds]\n",
    "\n",
    "            \n",
    "            y_pred_tmp = np.dot(X_tmp, W)\n",
    "            dQ = 2/len(y_tmp) * X_tmp.T @ (y_pred_tmp - y_tmp) # градиент функции ошибки\n",
    "            W -= (eta * dQ)\n",
    "            \n",
    "            err = calc_mse(y, np.dot(X, W))\n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stohastic_gradient_descent(X_st, y, iterations=5000, batch_size=4, eta=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819754c",
   "metadata": {},
   "source": [
    "#### L2 регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15109c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg_l2(X, y, iterations, eta=1e-4, reg=1e-8):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        y_pred = np.dot(X, W)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        \n",
    "        dQ = 2/n * X.T @ (y_pred - y) # градиент функции ошибки\n",
    "        dReg = reg * W # градиент регуляризации\n",
    "        \n",
    "        W -= eta * (dQ + dReg)\n",
    "        \n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ea881",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_reg_l2(X_st, y, iterations=5000, eta=1e-1, reg=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(X_st, y, iterations=5000, eta=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3da00",
   "metadata": {},
   "source": [
    "***1. Постройте график зависимости весов всех признаков от lambda в L2-регуляризации на основе данных из урока.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "n = 50\n",
    "\n",
    "train_amount = 5\n",
    "train_X = X[:train_amount]\n",
    "train_y = y[:train_amount]\n",
    "test_X = X[train_amount:]\n",
    "test_y = y[train_amount:]\n",
    "\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "\n",
    "coeffs = np.zeros((n, train_X.shape[1]))\n",
    "alpha_list = np.logspace(-3, 2, n)\n",
    "\n",
    "for i, val in enumerate(alpha_list):\n",
    "    ridge = Ridge(alpha=val, fit_intercept=False)\n",
    "    ridge.fit(train_X, train_y)\n",
    "    \n",
    "    coeffs[i, :] = ridge.coef_.flatten()\n",
    "    \n",
    "    coef = coeffs[i]\n",
    "    y_pred_tr = np.dot(train_X, coef)\n",
    "    mse_train.append(np.mean((y_pred_tr - train_y)**2))\n",
    "    y_pred_ts = np.dot(test_X, coef)\n",
    "    mse_test.append(np.mean((y_pred_ts - test_y)**2))\n",
    "\n",
    "\n",
    "for i in range(train_X.shape[1]):\n",
    "    plt.plot(alpha_list, coeffs[:, i])\n",
    "\n",
    "plt.title('Убывание абсолютных значений весов признаков\\n при увеличении коэффициента регуляризации alpha (Ridge)')\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Вес признака');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62aac67",
   "metadata": {},
   "source": [
    "***3. Напишите функцию наподобие eval_model_reg2, но для применения L1-регуляризации.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8465d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg_l1(X, y, iterations, eta=1e-4, reg=1e-8):\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        y_pred = np.dot(X, W)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        \n",
    "        dQ = 2/n * X.T @ (y_pred - y) # градиент функции ошибки\n",
    "        dReg = reg * np.sign(W) # градиент регуляризации\n",
    "        \n",
    "        W -= eta * (dQ + dReg)\n",
    "        \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(f'Iter: {i}, weights: {W}, error {err}')\n",
    "    \n",
    "    print(f'Final MSE: {calc_mse(y, np.dot(X, W))}')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80872be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_reg_l1(X_st, y, iterations=5000, eta=1e-2, reg=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e60f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
